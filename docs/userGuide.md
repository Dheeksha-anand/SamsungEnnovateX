# ğŸ“± On-Device Fine-Tuning Framework for LLMs (Mobile)

![App Screenshot](b4ea168c-e0b1-47d5-8df4-2dd2254d383c.png)

## ğŸ“Œ Overview
This project provides a framework for **on-device fine-tuning of billion+ parameter Large Language Models (LLMs)**.  
It is built around **TinyLLaMA (1.1B)** and optimized using **QLoRA adapters + llama.cpp** to enable **lightweight, private fine-tuning** directly on mobile devices (Android with Termux, portable to iOS).

---

## ğŸš€ Features
- ğŸ”’ **On-Device Fine-Tuning** â€“ No internet required, fully private.  
- ğŸ¯ **Dynamic Personalization** â€“ Fine-tune models with your own dataset.  
- âš¡ **Efficient Compression** â€“ QLoRA + Ridge Regression + SVD = tiny adapters.  
- ğŸ“² **Mobile Ready** â€“ Optimized with `llama.cpp` and `gguf`.  
- ğŸª¶ **Low Footprint** â€“ Adapters are only a few MBs, no retraining full model.  
- ğŸŒ **Cross-Platform** â€“ Works in Termux (Android), adaptable to iOS.  
- ğŸ”„ **Reversible Updates** â€“ Reset to base model anytime.  
- ğŸ–¥ï¸ **User-Friendly** â€“ Simple mobile interface for dataset input, fine-tune, and chat.  

---

## ğŸ› ï¸ Installation Guide

### 1. Requirements
- **Android phone** (4GB+ RAM recommended)  
- **Termux** (from F-Droid)  
- **Model files**:
  - `base_model.gguf` (TinyLLaMA 1.1B)  
  - `adapter.gguf` (trained adapter, optional)  

### 2. Setup Environment
Open **Termux** and run:
```bash
pkg update && pkg upgrade -y
pkg install git wget cmake build-essential python -y

###  Clone llama.cpp
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp
make

### Add Models

cp /sdcard/Downloads/base_model.gguf ~/llama.cpp/
cp /sdcard/Downloads/adapter.gguf ~/llama.cpp/
